{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import *\n",
        "from torchvision import transforms\n",
        "\n",
        "import nonechucks as nc\n",
        "\n",
        "from dataset.semcat import SEMCATDataset\n",
        "from dataset.semcat import OneVsAll, Text8Embedding\n",
        "from imbalanced_sampler import ImbalancedDatasetSampler\n",
        "from dnn import DNN"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TEST_SPLIT = 0.8\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 2\n",
        "LEARNING_RATE = 0.0001"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize SEMCAT dataset with Embedding transform"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = Text8Embedding('model.pkl')\n",
        "composition = transforms.Compose([\n",
        "    embedding\n",
        "])\n",
        "semcat = SEMCATDataset(transform=composition)\n",
        "semcat = nc.SafeDataset(semcat)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define function to train the classifiers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(semcat.dataset)\n",
        "dataset_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "9197"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classifier_accuracy(net, test_loader):\n",
        "    net.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            x, y = data['data'], data['category']\n",
        "            outputs = net(x)\n",
        "            predicted = round(outputs.data[0])\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "        return 100 * float(correct) / total"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_clf_for_category(category):\n",
        "    # Define net, loss function, and optimizer\n",
        "    net = DNN()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "    \n",
        "    # This will hold a list of classifiers - one for each SEMCAT category\n",
        "    classifiers = []\n",
        "    # List of indices\n",
        "    dataset_size = len(semcat)\n",
        "    indices = list(range(dataset_size))\n",
        "    \n",
        "    # Shuffle indices\n",
        "    random.shuffle(indices)\n",
        "    \n",
        "    # Initialize training dataloader\n",
        "    train_indices = indices[:int(TRAIN_TEST_SPLIT * dataset_size)]\n",
        "    train_sampler = nc.SafeSampler(semcat, SubsetRandomSampler(train_indices))\n",
        "    train_loader = nc.SafeDataLoader(\n",
        "        semcat,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    \n",
        "    # Train the neural network\n",
        "    for epoch in range(1):\n",
        "        running_loss = 0.0\n",
        "        for i_batch, batched_sample in enumerate(train_loader):\n",
        "            inputs, labels = batched_sample['data'], batched_sample['category']\n",
        "            labels = torch.autograd.Variable(labels).float()\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward + Backward + Optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "#           print(loss)\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Update running loss\n",
        "            running_loss += loss.item()\n",
        "            if i_batch % 100 == 99:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i_batch + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    \n",
        "    # Initialize test dataloader\n",
        "    test_indices = indices[int(TRAIN_TEST_SPLIT * dataset_size):]\n",
        "    test_sampler = nc.SafeSampler(semcat, SubsetRandomSampler(test_indices))\n",
        "    test_loader = nc.SafeDataLoader(\n",
        "        semcat,\n",
        "        sampler=test_sampler\n",
        "    )\n",
        "    accuracy = get_classifier_accuracy(net, test_loader)\n",
        "    print('Test Accuracy: {} %'.format(accuracy))\n",
        "    \n",
        "    classifiers.append(net)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For each SEMCAT category, train a classifier"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for category in SEMCATDataset.CATEGORY_FILES.keys():\n",
        "    print('Training for category: {}'.format(category))\n",
        "\n",
        "    # Convert multiclass labels into one-vs-all format\n",
        "    composition.transforms.append(OneVsAll(category))\n",
        "    train_clf_for_category(category)\n",
        "    composition.transforms.pop()\n",
        "    # TODO remove this to train for all categories\n",
        "    break"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for category: office\n",
            "[1,   100] loss: 0.410\n",
            "[1,   200] loss: 0.308\n",
            "[1,   300] loss: 0.287\n",
            "[1,   400] loss: 0.259\n",
            "[1,   500] loss: 0.265\n",
            "[1,   600] loss: 0.255\n",
            "[1,   700] loss: 0.254\n",
            "[1,   800] loss: 0.247\n",
            "[1,   900] loss: 0.217\n",
            "[1,  1000] loss: 0.230\n",
            "[1,  1100] loss: 0.194\n",
            "[1,  1200] loss: 0.235\n",
            "[1,  1300] loss: 0.209\n",
            "[1,  1400] loss: 0.222\n",
            "[1,  1500] loss: 0.200\n",
            "[1,  1600] loss: 0.219\n",
            "[1,  1700] loss: 0.158\n",
            "Finished Training\n",
            "Test Accuracy: 97.1760797342 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/msamogh/research/local/lib/python2.7/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/home/msamogh/research/local/lib/python2.7/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For each category, get average embedding value for each dimension"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "office_words_embeddings = np.array([word['data'] for word in semcat if word['category'] == 'office'])"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = len(office_words_embeddings[0])\n",
        "embedding_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_office_embedding = np.mean(office_words_embeddings, axis=0)"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "research"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15rc1",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "kernelspec": {
      "name": "research",
      "language": "python",
      "display_name": "Python (research)"
    },
    "nteract": {
      "version": "0.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}